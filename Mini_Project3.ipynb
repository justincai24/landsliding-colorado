{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "A_z_HnUY9ifx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c86eff5a-3190-4954-a121-54a25e02c31a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('tigers', 0.723923921585083),\n",
              " ('woods', 0.6852725148200989),\n",
              " ('warrior', 0.6822084188461304),\n",
              " ('ltte', 0.6664599776268005),\n",
              " ('wild', 0.6495702266693115),\n",
              " ('elephant', 0.6488102078437805),\n",
              " ('crocodile', 0.6469966173171997),\n",
              " ('leopard', 0.6459458470344543),\n",
              " ('eelam', 0.6417322754859924),\n",
              " ('warriors', 0.6396877765655518)]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "#1b\n",
        "#Dowwnload pre-trained genshim 'glove-wiki-gigaword-50' and print synonyms/similar words to 'tiger', 'awesome', 'song', 'data'\n",
        "import gensim.downloader as api\n",
        "\n",
        "glove_vectors = api.load('glove-wiki-gigaword-50')\n",
        "glove_vectors.most_similar('tiger')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "glove_vectors.most_similar('awesome')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIPc0yiP2XH_",
        "outputId": "0ff42015-f97f-406b-e146-5718b415afc0"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('unbelievable', 0.8638608455657959),\n",
              " ('amazing', 0.8620665073394775),\n",
              " ('incredible', 0.8470884561538696),\n",
              " ('fantastic', 0.8059698343276978),\n",
              " ('marvelous', 0.7899899482727051),\n",
              " ('terrific', 0.7802115678787231),\n",
              " ('phenomenal', 0.7445020079612732),\n",
              " ('truly', 0.7433545589447021),\n",
              " ('luck', 0.7240825891494751),\n",
              " ('damn', 0.7129141092300415)]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "glove_vectors.most_similar('song')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBO48PYH2ZMC",
        "outputId": "eaf11361-8db7-40e2-be63-54d4178f49f6"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('album', 0.9297007918357849),\n",
              " ('songs', 0.90098637342453),\n",
              " ('soundtrack', 0.8414768576622009),\n",
              " ('albums', 0.8228148221969604),\n",
              " ('pop', 0.8219155073165894),\n",
              " ('sings', 0.8201141357421875),\n",
              " ('tune', 0.8188669681549072),\n",
              " ('duet', 0.8186635971069336),\n",
              " ('remix', 0.8086214661598206),\n",
              " ('band', 0.8063262701034546)]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "glove_vectors.most_similar('data')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCiClUpd2aG3",
        "outputId": "e0162264-f464-41d7-8e79-49adc3711ffe"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('information', 0.8329989314079285),\n",
              " ('tracking', 0.8124600648880005),\n",
              " ('database', 0.8122305274009705),\n",
              " ('analysis', 0.7966611981391907),\n",
              " ('applications', 0.792366623878479),\n",
              " ('indicate', 0.7726754546165466),\n",
              " ('indicates', 0.7607492208480835),\n",
              " ('computer', 0.7605311274528503),\n",
              " ('indicating', 0.7578964233398438),\n",
              " ('user', 0.7567422986030579)]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1c\n",
        "#Use pre-trained genshim 'glove-wiki-gigaword-50' to find reasonable words to complete analogies\n",
        "glove_vectors.most_similar(negative=['puppy'], positive=['kitten', 'dog'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdZfTl1O3RVU",
        "outputId": "a98fcb81-8d42-4120-bdce-ea0d8f9f60c7"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('cat', 0.7508497834205627),\n",
              " ('monkey', 0.7091848850250244),\n",
              " ('mad', 0.6777215600013733),\n",
              " ('killer', 0.6767454147338867),\n",
              " ('monster', 0.6694737672805786),\n",
              " ('bikini', 0.6579682230949402),\n",
              " ('naked', 0.656236469745636),\n",
              " ('boy', 0.6555360555648804),\n",
              " ('girl', 0.6513919234275818),\n",
              " ('baby', 0.6496790051460266)]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "glove_vectors.most_similar(negative=['freshman'], positive=['sophomore', 'junior'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GC_BxnBh5fLt",
        "outputId": "f23a103c-1d60-4919-b64d-63f9effb1e1b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('basketball', 0.7672480344772339),\n",
              " ('player', 0.749573826789856),\n",
              " ('volleyball', 0.7307999134063721),\n",
              " ('championship', 0.7298742532730103),\n",
              " ('varsity', 0.7285652160644531),\n",
              " ('played', 0.7253320813179016),\n",
              " ('team', 0.7120876312255859),\n",
              " ('football', 0.7112278342247009),\n",
              " ('coached', 0.709040641784668),\n",
              " ('championships', 0.7007246017456055)]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "glove_vectors.most_similar(negative=['brother'], positive=['sister', 'grandson'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uB3XIor_5rg3",
        "outputId": "f742c834-af17-4dfc-8b74-3b9f2204f771"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('granddaughter', 0.8704105615615845),\n",
              " ('daughter', 0.8524291515350342),\n",
              " ('niece', 0.8365100026130676),\n",
              " ('grandmother', 0.8078756928443909),\n",
              " ('aunt', 0.8066101670265198),\n",
              " ('mother', 0.783445417881012),\n",
              " ('daughters', 0.7791755795478821),\n",
              " ('wife', 0.7782493233680725),\n",
              " ('widow', 0.7730810642242432),\n",
              " ('mary', 0.7610968351364136)]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2a\n",
        "#Prepare \"fake-news\" corpus\n",
        "corpus_data = api.load(\"fake-news\")\n",
        "docs = [x['text'] for x in corpus_data]"
      ],
      "metadata": {
        "id": "V20OIPdL5w7X"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2b and c\n",
        "#Adapted from https://radimrehurek.com/gensim/auto_examples/tutorials/run_lda.html\n",
        "# Tokenize the documents.\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "# Split the documents into tokens.\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "for idx in range(len(docs)):\n",
        "    docs[idx] = docs[idx].lower()  # Convert to lowercase.\n",
        "    docs[idx] = tokenizer.tokenize(docs[idx])  # Split into words.\n",
        "\n",
        "# Remove numbers, but not words that contain numbers.\n",
        "docs = [[token for token in doc if not token.isnumeric()] for doc in docs]\n",
        "\n",
        "# Remove words that are only one character.\n",
        "docs = [[token for token in doc if len(token) > 1] for doc in docs]"
      ],
      "metadata": {
        "id": "Xk-PhUxe_SQQ"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "# Lemmatize the documents.\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "docs = [[lemmatizer.lemmatize(token) for token in doc] for doc in docs]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fybXMd1FAwyM",
        "outputId": "9b2f7e34-7206-40c3-b895-c0ed81a6552a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute bigrams.\n",
        "from gensim.models import Phrases\n",
        "\n",
        "# Add bigrams and trigrams to docs (only ones that appear 20 times or more).\n",
        "bigram = Phrases(docs, min_count=20)\n",
        "for idx in range(len(docs)):\n",
        "    for token in bigram[docs[idx]]:\n",
        "        if '_' in token:\n",
        "            # Token is a bigram, add to document.\n",
        "            docs[idx].append(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pf9qlmKA1hA",
        "outputId": "2c31c957-43d7-471a-abdd-485fee45fd44"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove rare and common tokens.\n",
        "from gensim.corpora import Dictionary\n",
        "\n",
        "# Create a dictionary representation of the documents.\n",
        "dictionary = Dictionary(docs)\n",
        "\n",
        "# Filter out words that occur less than 20 documents, or more than 50% of the documents.\n",
        "dictionary.filter_extremes(no_below=20, no_above=0.5)"
      ],
      "metadata": {
        "id": "mD_9wqZNA3up"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bag-of-words representation of the documents.\n",
        "corpus = [dictionary.doc2bow(doc) for doc in docs]"
      ],
      "metadata": {
        "id": "qr6qV6jVA55O"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Number of unique tokens: %d' % len(dictionary))\n",
        "print('Number of documents: %d' % len(corpus))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0BdWVVKBAL2",
        "outputId": "37949337-88ea-410f-8cd1-430a86fc6413"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique tokens: 18332\n",
            "Number of documents: 12999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2d\n",
        "# Train LDA model.\n",
        "from gensim.models import LdaModel\n",
        "\n",
        "# Set training parameters.\n",
        "num_topics = 3\n",
        "chunksize = 13000\n",
        "passes = 20\n",
        "iterations = 400\n",
        "eval_every = None  # Don't evaluate model perplexity, takes too much time.\n",
        "\n",
        "# Make an index to word dictionary.\n",
        "temp = dictionary[0]  # This is only to \"load\" the dictionary.\n",
        "id2word = dictionary.id2token\n",
        "\n",
        "model = LdaModel(\n",
        "    corpus=corpus,\n",
        "    id2word=id2word,\n",
        "    chunksize=chunksize,\n",
        "    alpha='auto',\n",
        "    eta='auto',\n",
        "    iterations=iterations,\n",
        "    num_topics=num_topics,\n",
        "    passes=passes,\n",
        "    eval_every=eval_every\n",
        ")"
      ],
      "metadata": {
        "id": "gCT2vJxkCBat"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_topics = model.top_topics(corpus)\n",
        "\n",
        "# Average topic coherence is the sum of topic coherences of all topics, divided by the number of topics.\n",
        "avg_topic_coherence = sum([t[1] for t in top_topics]) / num_topics\n",
        "print('Average topic coherence: %.4f.' % avg_topic_coherence)\n",
        "\n",
        "from pprint import pprint\n",
        "pprint(top_topics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iCbR-0OGXOY",
        "outputId": "0312abf2-d527-4b32-a74e-b76c983a07f9"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average topic coherence: -0.9699.\n",
            "[([(0.01097569, 'you'),\n",
            "   (0.00520073, 'can'),\n",
            "   (0.0050359075, 'people'),\n",
            "   (0.0047298176, 'he'),\n",
            "   (0.004691833, 'what'),\n",
            "   (0.0043817, 'more'),\n",
            "   (0.0043469556, 'our'),\n",
            "   (0.004283745, 'if'),\n",
            "   (0.0042156414, 'there'),\n",
            "   (0.0042095953, 'your'),\n",
            "   (0.0040178876, 'so'),\n",
            "   (0.0038339347, 'which'),\n",
            "   (0.0035430817, 'his'),\n",
            "   (0.0035102412, 'when'),\n",
            "   (0.0034719734, 'were'),\n",
            "   (0.0034661826, 'year'),\n",
            "   (0.003416106, 'time'),\n",
            "   (0.0033504185, 'no'),\n",
            "   (0.0031664544, 'out'),\n",
            "   (0.003105196, 'up')],\n",
            "  -0.48318480346634046),\n",
            " ([(0.013131264, 'clinton'),\n",
            "   (0.013121551, 'trump'),\n",
            "   (0.009393169, 'he'),\n",
            "   (0.008113185, 'hillary'),\n",
            "   (0.0065875957, 'his'),\n",
            "   (0.006285922, 'her'),\n",
            "   (0.0061645876, 'election'),\n",
            "   (0.0056379437, 'she'),\n",
            "   (0.004424137, 'email'),\n",
            "   (0.0043656887, 'state'),\n",
            "   (0.0042279297, 'hillary_clinton'),\n",
            "   (0.004038875, 'would'),\n",
            "   (0.003929698, 'if'),\n",
            "   (0.0039060963, 'president'),\n",
            "   (0.0036733584, 'campaign'),\n",
            "   (0.0036376968, 'said'),\n",
            "   (0.003587025, 'what'),\n",
            "   (0.00355917, 'you'),\n",
            "   (0.0035152715, 'american'),\n",
            "   (0.0034529855, 'donald')],\n",
            "  -0.630977582000527),\n",
            " ([(0.010385956, 'de'),\n",
            "   (0.008386442, 'russia'),\n",
            "   (0.008236718, 'u'),\n",
            "   (0.0072352937, 'war'),\n",
            "   (0.0062227435, 'la'),\n",
            "   (0.0060624112, 'russian'),\n",
            "   (0.005273194, 'syria'),\n",
            "   (0.004852219, 'state'),\n",
            "   (0.00443509, 'military'),\n",
            "   (0.004263528, 'obama'),\n",
            "   (0.0038825027, 'al'),\n",
            "   (0.0034853732, 'no'),\n",
            "   (0.0034384758, 'government'),\n",
            "   (0.0034167413, 'force'),\n",
            "   (0.0033122976, 'el'),\n",
            "   (0.0032268688, 'en'),\n",
            "   (0.0031643359, 'country'),\n",
            "   (0.0030911856, 'que'),\n",
            "   (0.0030726856, 'president'),\n",
            "   (0.0029547422, 'said')],\n",
            "  -1.795475978911357)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3a\n",
        "#Adapted from precept 9 material\n",
        "## Import Keras and Tensorflow\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "1GN4POE4J9vd"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Defines the Neural Network model\n",
        "inputs = keras.Input(shape=(784,))\n",
        "x = layers.Dense(32, activation=\"relu\")(inputs)\n",
        "x = layers.Dense(32, activation=\"relu\")(x)\n",
        "outputs = layers.Dense(32, activation=\"softmax\")(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "metadata": {
        "id": "pxCBFRVAKUdF"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Load the builtin MNIST data\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Reserve 10,000 samples for validation\n",
        "x_val = x_train[-10000:]\n",
        "y_val = y_train[-10000:]\n",
        "x_train = x_train[:-10000]\n",
        "y_train = y_train[:-10000]"
      ],
      "metadata": {
        "id": "asniRspuKTsM"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the data (these are NumPy arrays)\n",
        "x_train = x_train.reshape(-1, 784).astype(\"float32\") / 255\n",
        "x_test = x_test.reshape(-1, 784).astype(\"float32\") / 255\n",
        "x_val = x_val.reshape(-1, 784).astype(\"float32\") / 255"
      ],
      "metadata": {
        "id": "SLBLrQYjLsZC"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Prepare the model with additional information about how to train it!  (i.e. \"compile\" it)\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.RMSprop(),  # Optimizer Adam\n",
        "    # Loss function to minimize\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "    # List of metrics to monitor\n",
        "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        ")"
      ],
      "metadata": {
        "id": "W0dyJC-tLv9w"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3b\n",
        "## Fit our model with the initial training data, and check it with the \"validation\" training data!\n",
        "print(\"Fit model on training data\")\n",
        "history = model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=64,\n",
        "    epochs=5,\n",
        "    # We pass some validation for\n",
        "    # monitoring validation loss and metrics\n",
        "    # at the end of each epoch\n",
        "    validation_data=(x_val, y_val),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSnb4BB7LyqL",
        "outputId": "8792493f-d51c-4925-8fe0-01ec1e3c64e6"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fit model on training data\n",
            "Epoch 1/5\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 0.4577 - sparse_categorical_accuracy: 0.8742 - val_loss: 0.2366 - val_sparse_categorical_accuracy: 0.9320\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 0.2280 - sparse_categorical_accuracy: 0.9321 - val_loss: 0.1856 - val_sparse_categorical_accuracy: 0.9484\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 0.1764 - sparse_categorical_accuracy: 0.9479 - val_loss: 0.1554 - val_sparse_categorical_accuracy: 0.9569\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 0.1473 - sparse_categorical_accuracy: 0.9567 - val_loss: 0.1509 - val_sparse_categorical_accuracy: 0.9573\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 0.1281 - sparse_categorical_accuracy: 0.9618 - val_loss: 0.1440 - val_sparse_categorical_accuracy: 0.9594\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmTpyPz0dN9_",
        "outputId": "eecc2660-fc9f-4b33-af1f-7d07b844d6c4"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 784)]             0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 32)                25120     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 32)                1056      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 32)                1056      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 27,232\n",
            "Trainable params: 27,232\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history.history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3Szk7oMdRoa",
        "outputId": "057024a3-4f09-4150-a0f3-d2e61d6ea8e9"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': [0.4577403664588928,\n",
              "  0.22801083326339722,\n",
              "  0.17637427151203156,\n",
              "  0.14734302461147308,\n",
              "  0.12809112668037415],\n",
              " 'sparse_categorical_accuracy': [0.8741999864578247,\n",
              "  0.9320999979972839,\n",
              "  0.9479399919509888,\n",
              "  0.9567199945449829,\n",
              "  0.9618399739265442],\n",
              " 'val_loss': [0.23659172654151917,\n",
              "  0.18561935424804688,\n",
              "  0.15535879135131836,\n",
              "  0.1508597433567047,\n",
              "  0.14399048686027527],\n",
              " 'val_sparse_categorical_accuracy': [0.9319999814033508,\n",
              "  0.9484000205993652,\n",
              "  0.9569000005722046,\n",
              "  0.9573000073432922,\n",
              "  0.9593999981880188]}"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the training data using `evaluate`\n",
        "print(\"Evaluate on training data\")\n",
        "results = model.evaluate(x_train, y_train, batch_size=128)\n",
        "print(\"loss, accuracy:\", results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUC23NCre-Yp",
        "outputId": "b00ec439-2d33-43b6-dba5-c227fa4d9df7"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluate on training data\n",
            "391/391 [==============================] - 1s 2ms/step - loss: 0.1278 - sparse_categorical_accuracy: 0.9618\n",
            "loss, accuracy: [0.12779346108436584, 0.9617800116539001]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the validation data using `evaluate`\n",
        "print(\"Evaluate on validation data\")\n",
        "results = model.evaluate(x_val, y_val, batch_size=128)\n",
        "print(\"loss, accuracy:\", results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBFz14f-fFX1",
        "outputId": "301c24c0-2daf-460f-be5c-f80755f1194f"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluate on validation data\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.1440 - sparse_categorical_accuracy: 0.9594\n",
            "loss, accuracy: [0.14399048686027527, 0.9593999981880188]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test data using `evaluate`\n",
        "print(\"Evaluate on test data\")\n",
        "results = model.evaluate(x_test, y_test, batch_size=128)\n",
        "print(\"loss, accuracy:\", results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCWUmSyfdWdh",
        "outputId": "97a58e38-f3e0-41f3-f155-02a082b113ef"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluate on test data\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.1493 - sparse_categorical_accuracy: 0.9544\n",
            "loss, accuracy: [0.14929945766925812, 0.9544000029563904]\n"
          ]
        }
      ]
    }
  ]
}